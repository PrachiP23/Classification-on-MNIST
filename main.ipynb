{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "FLAGS = None\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage.color import rgb2gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    # Import data\n",
    "    mnist = input_data.read_data_sets('./MNIST_Logistic', one_hot=True)\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    y = tf.matmul(x, W) + b\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # The raw formulation of cross-entropy,\n",
    "    #\n",
    "    #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n",
    "    #                                 reduction_indices=[1]))\n",
    "    #\n",
    "    # can be numerically unstable.\n",
    "    #\n",
    "    # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "    # outputs of 'y', and then average across the batch.\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "    #train_step = tf.train.AdagradOptimizer(0.9).minimize(cross_entropy)\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    error=[]\n",
    "    # Train\n",
    "    for i in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        if i%10 == 0:\n",
    "            error.append(sess.run(cross_entropy, feed_dict={x: batch_xs, y_: batch_ys}))\n",
    "      # Test trained model\n",
    "\n",
    "    plt.plot(error)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Error')\n",
    "    plt.show()\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Logistic Regression:\")\n",
    "    print(\"Logistic Regression Train Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      y_: mnist.test.labels}))\n",
    "\n",
    "    path = \"..\\proj3_images\\Test\"\n",
    "    path += \"\\\\\"\n",
    "    arr = os.listdir(path)\n",
    "    test_images = np.zeros((1500, 784))\n",
    "    test_y_ = [] #tf.placeholder(tf.float32, [None, 10])\n",
    "    i=0;\n",
    "    for idx, filenames in enumerate(arr):\n",
    "        if '.png' in filenames:\n",
    "            label = filenames.split(\"_\")[1]\n",
    "            label = int(label.split(\".\")[0]) \n",
    "            ix = int(10 - math.ceil(label/150))\n",
    "            image_labels = np.zeros((1,10))\n",
    "            image_labels[0,ix] = 1 \n",
    "            test_y_.append(image_labels)\n",
    "\n",
    "            filenames = path+filenames\n",
    "            img = Image.open(filenames)\n",
    "\n",
    "            img = img.resize((28,28), Image.NEAREST)\n",
    "            #img.mode = 'L'\n",
    "            img = np.asarray(img, dtype=np.float32)\n",
    "            img = rgb2gray(img)\n",
    "            test_images[idx,0:784] = img.flatten()\n",
    "            i+=1\n",
    "\n",
    "\n",
    "    test_y_ = np.asarray(test_y_, dtype=np.float32)\n",
    "    test_y_ = np.squeeze(test_y_)\n",
    "\n",
    "    test_images = 1.0 - test_images / 255.0\n",
    "    test_images = np.asarray(test_images, dtype=np.float32)    \n",
    "\n",
    "    print(\"Logistic Regression USPS Test accuracy:\", sess.run(accuracy, feed_dict={x: test_images,y_: test_y_}))\n",
    "    \n",
    "    path = \"..\\proj3_images\\\\Numerals\"\n",
    "    path += \"\\\\\"\n",
    "    arr = os.listdir(path)\n",
    "    test_images1 = np.zeros((19999, 784))\n",
    "    test_y_1 = [] #tf.placeholder(tf.float32, [None, 10])\n",
    "    i=0;\n",
    "    for idx, label1 in enumerate(arr):\n",
    "        image_path = path + \"\\\\\"\n",
    "        image_path += label1\n",
    "        image_path += \"\\\\\"\n",
    "        arr1 = os.listdir(image_path)\n",
    "        for filenames in arr1:\n",
    "            if '.png' in filenames:\n",
    "                image_labels = np.zeros((1,10))\n",
    "                image_labels[0,idx] = 1 \n",
    "                test_y_1.append(image_labels)\n",
    "                filenames = image_path+filenames\n",
    "                img = Image.open(filenames)\n",
    "                img = img.resize((28,28), Image.NEAREST)\n",
    "                img = np.asarray(img, dtype=np.float32)\n",
    "                img = rgb2gray(img)\n",
    "                test_images1[idx,0:784] = img.flatten()\n",
    "\n",
    "\n",
    "    test_y_1 = np.asarray(test_y_1, dtype=np.float32)\n",
    "    test_y_1 = np.squeeze(test_y_1)\n",
    "\n",
    "    test_images1 = 1 - test_images1 / 255.0\n",
    "    test_images1 = np.asarray(test_images1, dtype=np.float32)\n",
    "\n",
    "    print(\"Logistic Regression Numerals Folder Test Accuracy:\", sess.run(accuracy, feed_dict={x: test_images1, y_: test_y_1}))\n",
    "    \n",
    "    print('MLP:')\n",
    "\n",
    "    #mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    "    # Create model\n",
    "    # Add more hidden layers to create deeper networks\n",
    "    # Remember to connect the final hidden layer to the out_layer\n",
    "    def create_multilayer_perceptron():\n",
    "        # Network Parameters\n",
    "        n_hidden_1 = 40  # 1st layer number of features\n",
    "        n_input = 784  # data input\n",
    "        n_classes = 10\n",
    "\n",
    "        # Store layers weight & bias\n",
    "        weights = {\n",
    "            'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "            'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes]))\n",
    "        }\n",
    "        biases = {\n",
    "            'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "            'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "        }\n",
    "        # tf Graph input\n",
    "        x = tf.placeholder(\"float32\", [None, n_input])\n",
    "        y = tf.placeholder(\"float32\", [None, n_classes])\n",
    "\n",
    "\n",
    "        # Hidden layer with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "        # Output layer with linear activation\n",
    "        out_ = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "        out_layer = tf.nn.softmax(out_)\n",
    "        return out_layer,x,y\n",
    "\n",
    "\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 0.01\n",
    "    training_epochs = 50\n",
    "    batch_size = 100\n",
    "\n",
    "    # Construct model\n",
    "    pred,x,y = create_multilayer_perceptron()\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Launch the graph\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    error=[]\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "            avg_cost = 0.\n",
    "            # Loop over all batches\n",
    "            for i in range(1000):\n",
    "                batch_x, batch_y = mnist.train.next_batch(100)\n",
    "                # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "                error.append(cost)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"MLP test Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "    print(\"MLP USPS Test Accuracy:\" , sess.run(accuracy, feed_dict={x: test_images, y: test_y_}))\n",
    "    print(\"MLP Numerals folder test Accuracy:\", sess.run(accuracy, feed_dict={x: test_images1, y: test_y_1}))\n",
    "    \n",
    "    print(\"CNN:\")\n",
    "    def deepnn(x):\n",
    "      \"\"\"deepnn builds the graph for a deep net for classifying digits.\n",
    "      Args:\n",
    "        x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n",
    "        number of pixels in a standard MNIST image.\n",
    "      Returns:\n",
    "        A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n",
    "        equal to the logits of classifying the digit into one of 10 classes (the\n",
    "        digits 0-9). keep_prob is a scalar placeholder for the probability of\n",
    "        dropout.\n",
    "      \"\"\"\n",
    "      # Reshape to use within a convolutional neural net.\n",
    "      # Last dimension is for \"features\" - there is only one here, since images are\n",
    "      # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "      with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "      # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "      with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "      # Pooling layer - downsamples by 2X.\n",
    "      with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "      # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "      with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "      # Second pooling layer.\n",
    "      with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "      # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "      # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "      with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "      # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "      # features.\n",
    "      with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "      # Map the 1024 features to 10 classes, one for each digit\n",
    "      with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([1024, 10])\n",
    "        b_fc2 = bias_variable([10])\n",
    "\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "      return y_conv, keep_prob\n",
    "\n",
    "\n",
    "    def conv2d(x, W):\n",
    "      \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "    def max_pool_2x2(x):\n",
    "      \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "    def weight_variable(shape):\n",
    "      \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "      initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "      return tf.Variable(initial)\n",
    "\n",
    "\n",
    "    def bias_variable(shape):\n",
    "      \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "      initial = tf.constant(0.1, shape=shape)\n",
    "      return tf.Variable(initial)\n",
    "\n",
    "\n",
    "    # Import data\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # Build the graph for the deep net\n",
    "    y_conv, keep_prob = deepnn(x)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                                logits=y_conv)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('adam_optimizer'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "      # sess.run(tf.global_variables_initializer())\n",
    "    for i in range(20000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            #print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('CNN test accuracy for mnist %g' % sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    print(\"CNN USPS Test Accuracy:\", sess.run(accuracy, feed_dict={x: test_images, y_: test_y_, keep_prob: 1.0}))\n",
    "    print(\"CNN Numerals Folder Test Accuracy\", sess.run(accuracy, feed_dict={x: test_images1,y_: test_y_1, keep_prob : 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-553748f9992d>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_Logistic\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_Logistic\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./MNIST_Logistic\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./MNIST_Logistic\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-2-553748f9992d>:24: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x271aa0e5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Logistic Regression Train Accuracy: 0.8712\n",
      "Logistic Regression USPS Test accuracy: 0.29666665\n",
      "Logistic Regression Numerals Folder Test Accuracy: 0.099955\n",
      "MLP:\n",
      "MLP test Accuracy: 0.7759\n",
      "MLP USPS Test Accuracy: 0.332\n",
      "MLP Numerals folder test Accuracy: 0.100005\n",
      "CNN:\n",
      "CNN test accuracy for mnist 0.9932\n",
      "CNN USPS Test Accuracy: 0.7\n",
      "CNN Numerals Folder Test Accuracy 0.100005\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prach\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',\n",
    "                      help='Directory for storing input data')\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
